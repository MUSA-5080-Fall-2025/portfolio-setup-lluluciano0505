{
  "hash": "10ca4df27a46ca6f184ca7d385647d58",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Midterm Challenge: Philadelphia Housing Price Prediction\"\nsubtitle: \"MUSA 5080 - Public Policy Analytics\"\nformat: \n  html:\n    toc: true\n    toc-location: left\n    code-fold: show\n    theme: cosmo\n---\n\n## Overview\n\n**Due Date:** October 27, 2025\n\n**In-Class Presentations:** October 27, 2025 (5 minutes per team)\n\n**Weight:** 15% of final grade\n\n**Team:** You'll work with your table-mates as a team. Feel free to delegate. Everyone should upload their final products onto their own portfolio websites. Be sure to acknowledge your team-mates.\n\n**Submission Format:**\n\n1. **Presentation Slides** (.qmd → revealjs, ~10-15 slides) - Main deliverable (see my weekly lecture notes for inspiration!)\n2. **Technical Appendix** (.qmd → HTML document) - Supporting details\n\n---\n\n## The Challenge\n\nYou are consultancy (please name your consultancy) competing to win the bid to work for a project for the **Philadelphia Office of Property Assessment**. The city wants to improve its Automated Valuation Model (AVM) for property tax assessments. Your task is to build a predictive model for residential sale prices and **present your findings** to city officials in a 5-minute briefing. \n\n**Deliverables:**\n\n1. **Presentation slides** (10-15 slides MAX) - Your main findings for stakeholders\n2. **Technical appendix** (HTML document) - All code, diagnostics, and detailed analysis\n3. **5-minute in-class presentation** - Deliver your slides on October 27th\n\n**Your goal:** Predict 2023-2024 home sale prices accurately while communicating findings clearly to a policy audience.\n\n---\n\n## Two-Part Submission\n\n### Part A: Presentation Slides (Primary Deliverable)\n\n**Format:** Quarto revealjs presentation\n\n**Example YAML:**\n```yaml\n---\ntitle: \"Philadelphia Housing Price Prediction\"\nsubtitle: \"Improving Property Tax Assessments\"\nauthor: \"Your Name\"\nformat: \n  revealjs:\n    theme: simple\n    slide-number: true\n    smaller: true\n---\n```\n\n**Content:** ~10-15 (could be less!!) slides covering:\n1. Research question & motivation (1-2 slides)\n2. Data overview (1 slide)\n3. Key visualizations (2-3 slides)\n4. Model comparison results (1-2 slides)\n5. Main findings (2-3 slides)\n6. Policy recommendations (1-2 slides)\n\n**Audience:** City officials who don't know R or care about the nitty gritty of stats. They just want the best estimates possible. \n\n**No code** in these slides - just polished visualizations and key takeaways\n\n---\n\n### Part B: Technical Appendix (Supporting Documentation)\n\n**Format:** Quarto HTML document\n\n**Example YAML:**\n```yaml\n---\ntitle: \"Philadelphia Housing Model - Technical Appendix\"\nauthor: \"Your Name\"\nformat: \n  html:\n    code-fold: show\n    toc: true\n    toc-location: left\n    theme: cosmo\n---\n```\n\n**Content:** All the technical details:\n- Complete data cleaning code\n- All EDA visualizations\n- Feature engineering code\n- Full model outputs\n- Diagnostic plots\n- Detailed interpretations\n\n**Audience:** Data scientists and technical reviewers\n\n**All code visible** - this is where you show your work\n\n---\n\n## Data Sources\n\n### Primary Dataset: Philadelphia Property Sales\n\n**Source:** [Philadelphia Property Sales](https://metadata.phila.gov/#home/datasetdetails/5543865f20583086178c4ee5/representationdetails/55d624fdad35c7e854cb21a4/)\n\nThis dataset contains actual property sales with:\n\n- Sale price\n- Sale date\n- Property characteristics (bedrooms, bathrooms, sq ft, etc.)\n- Property location (address, coordinates)\n\n**You will need to:**\n\n- Download the data\n- Clean it (missing values, outliers, data errors)\n- Filter to 2023-2024 residential sales only\n\n\n### Secondary Datasets (You Choose!)\n\n**Required:** Browse the OpenPhily Data portal and use Census Data to incorporate spatial features into your model.\n\n**Your task:** Think like an urban planner. What location factors matter for housing prices in Philadelphia?\n\n---\n\n## Assignment Structure\n\nYour work should follow this workflow, with results split between presentation and appendix:\n\n### Phase 1: Data Preparation (Technical Appendix)\n\n**Load and clean Philadelphia sales data:**\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Load necessary libraries\nlibrary(tidyverse)\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nWarning: package 'tidyverse' was built under R version 4.4.3\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\nWarning: package 'ggplot2' was built under R version 4.4.3\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\nWarning: package 'dplyr' was built under R version 4.4.2\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   4.0.0     ✔ tibble    3.2.1\n✔ lubridate 1.9.3     ✔ tidyr     1.3.1\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (<http://conflicted.r-lib.org/>) to force all conflicts to become errors\n```\n\n\n:::\n\n```{.r .cell-code}\nlibrary(sf)\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nWarning: package 'sf' was built under R version 4.4.2\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\nLinking to GEOS 3.13.0, GDAL 3.10.1, PROJ 9.5.1; sf_use_s2() is TRUE\n```\n\n\n:::\n\n```{.r .cell-code}\nlibrary(tidycensus)\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nWarning: package 'tidycensus' was built under R version 4.4.3\n```\n\n\n:::\n\n```{.r .cell-code}\nlibrary(tigris)\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nWarning: package 'tigris' was built under R version 4.4.3\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\nTo enable caching of data, set `options(tigris_use_cache = TRUE)`\nin your R script or .Rprofile.\n```\n\n\n:::\n\n```{.r .cell-code}\noptions(tigris_use_cache = TRUE, tigris_class = \"sf\")\nlibrary(MASS)\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nWarning: package 'MASS' was built under R version 4.4.3\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\n\nAttaching package: 'MASS'\n\nThe following object is masked from 'package:dplyr':\n\n    select\n```\n\n\n:::\n\n```{.r .cell-code}\nlibrary(dplyr)\nlibrary(scales)\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nWarning: package 'scales' was built under R version 4.4.3\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\n\nAttaching package: 'scales'\n\nThe following object is masked from 'package:purrr':\n\n    discard\n\nThe following object is masked from 'package:readr':\n\n    col_factor\n```\n\n\n:::\n\n```{.r .cell-code}\nlibrary(ggplot2)\nlibrary(caret)\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nWarning: package 'caret' was built under R version 4.4.3\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\nLoading required package: lattice\n\nAttaching package: 'caret'\n\nThe following object is masked from 'package:purrr':\n\n    lift\n```\n\n\n:::\n:::\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Load primary sales data\nopa <- read_csv(\"~/Datasets for r Trainning/opa_properties_public.csv\")\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nWarning: One or more parsing issues, call `problems()` on your data frame for details,\ne.g.:\n  dat <- vroom(...)\n  problems(dat)\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\nRows: 583776 Columns: 79\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr  (38): basements, beginning_point, book_and_page, building_code, buildin...\ndbl  (31): objectid, category_code, census_tract, depth, exempt_building, ex...\nlgl   (7): cross_reference, date_exterior_condition, mailing_address_2, mark...\ndttm  (3): assessment_date, recording_date, sale_date\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n```\n\n\n:::\n\n```{.r .cell-code}\nopa_clean <- opa %>%\n  mutate(sale_date = as.Date(sale_date)) %>%\n  filter(between(sale_date, as.Date(\"2023-01-01\"), as.Date(\"2024-12-31\")))\nread_csv(\"~/Datasets for r Trainning/opa_properties_public.csv\", show_col_types = FALSE)\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nWarning: One or more parsing issues, call `problems()` on your data frame for details,\ne.g.:\n  dat <- vroom(...)\n  problems(dat)\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 583,776 × 79\n    objectid assessment_date     basements beginning_point         book_and_page\n       <dbl> <dttm>              <chr>     <chr>                   <chr>        \n 1 695547670 2024-05-31 01:05:37 D         \"90' W 21 ST\"           54472500     \n 2 695547671 2024-05-31 01:05:37 <NA>      \"360'7 1/2\\\" W OF 20TH\" 54472278     \n 3 695547672 2024-05-31 01:05:37 <NA>      \"313'6\\\" N OF MORSE ST\" 54472444     \n 4 695547673 2024-05-31 01:05:37 0         \"SEC BIRWOOD ST\"        54472241     \n 5 695547674 2024-05-31 01:05:37 D         \"61'8\\\" W OF 19TH ST\"   54472329     \n 6 695547675 2024-05-31 01:05:37 <NA>      \"SEC BOUIER ST\"         54472270     \n 7 695547676 2024-05-31 01:05:37 <NA>      \"51'6\\\"N JEFFERSON ST\"  54472399     \n 8 695547677 2024-05-31 01:05:37 J         \"144' S TASKER ST\"      54472391     \n 9 695547678 2024-05-31 01:05:37 <NA>      \"SWC OXFORD ST\"         54472437     \n10 695547679 2024-05-31 01:05:37 <NA>      \"238' W BROAD ST\"       54472359     \n# ℹ 583,766 more rows\n# ℹ 74 more variables: building_code <chr>, building_code_description <chr>,\n#   category_code <dbl>, category_code_description <chr>, census_tract <dbl>,\n#   central_air <chr>, cross_reference <lgl>, date_exterior_condition <lgl>,\n#   depth <dbl>, exempt_building <dbl>, exempt_land <dbl>,\n#   exterior_condition <dbl>, fireplaces <dbl>, frontage <dbl>, fuel <chr>,\n#   garage_spaces <dbl>, garage_type <dbl>, general_construction <chr>, …\n```\n\n\n:::\n:::\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Select relevant variables\nopa_selected <- opa_clean %>%\n  dplyr::select(\n    sale_date, sale_price, market_value, building_code_description,\n    total_livable_area, number_of_bedrooms, number_of_bathrooms,\n    number_stories, garage_spaces, central_air, quality_grade,\n    interior_condition, exterior_condition, year_built,\n    zip_code, geographic_ward, census_tract, zoning, owner_1,\n    category_code_description, shape\n  ) %>%\n  filter(category_code_description == \"SINGLE FAMILY\") %>%\n  distinct() %>%\n  filter(\n    !is.na(sale_price) & sale_price > 1000 & sale_price < 1e8,\n    !is.na(total_livable_area) & total_livable_area > 0,\n    !is.na(year_built) & year_built > 1800 & year_built <= 2025\n  )\n```\n:::\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Transform to sf object\nopa_sf <- st_as_sf(opa_selected, wkt = \"shape\", crs = 2272) %>%\n  st_transform(4326)\n\n# Create new variable: house age\nopa_sf <- opa_sf %>%\n  mutate(\n    house_age = 2025 - year_built\n  ) %>%\n  filter(house_age >= 0 & house_age <= 200)\n\nopa_sf$central_air <- ifelse(opa_sf$central_air %in% c(\"Y\", \"1\"), 1,\n                           ifelse(opa_sf$central_air %in% c(\"N\", \"0\"), 0, NA))\n```\n:::\n\n\n\n**Load secondary data:**\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Load Census data for Philadelphia tracts\nphilly_census <- get_acs(\n  geography = \"tract\",\n  variables = c(\n    total_pop = \"B01003_001\",\n    white_pop = \"B02001_002\",\n    asian_pop = \"B02001_005\",\n    \n    ba_degree = \"B15003_022\",\n    total_edu = \"B15003_001\",\n    \n    median_income = \"B19013_001\",\n    poverty_pop = \"B17001_002\",\n    \n    labor_force = \"B23025_003\",\n    unemployed = \"B23025_005\"\n  ),\n  year = 2023,\n  state = \"PA\",\n  county = \"Philadelphia\",\n  geometry = TRUE\n) %>%\n  dplyr::select(GEOID, variable, estimate, geometry) %>%   # ← 用 dplyr::\n  tidyr::pivot_wider(names_from = variable, values_from = estimate) %>%\n  dplyr::mutate(\n    white_share = 100 * white_pop / total_pop,\n    asian_share = 100 * asian_pop / total_pop,\n    ba_rate = 100 * ba_degree / total_edu,\n    unemployment_rate = 100 * unemployed / labor_force,\n    poverty_rate = 100 * poverty_pop / total_pop\n  ) %>%\n  st_transform(st_crs(opa_sf))\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nGetting data from the 2019-2023 5-year ACS\n```\n\n\n:::\n:::\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Spatial join of OPA data with Census data\nopa_census <- st_join(opa_sf, philly_census, join = st_within) %>%\n  filter(!is.na(median_income))\n```\n:::\n\n\n**Deliverable (Appendix only):**\n\nThis section documents the data cleaning and preparation process for the Philadelphia housing dataset used in our modeling analysis.\n\nDeliverables include:\n\n✅ Complete data cleaning code: full R pipeline from raw OPA property sales to a cleaned, spatially joined dataset ready for modeling.\n\n✅ Summary tables showing before/after dimensions: record counts before and after filtering, demonstrating how outliers, missing values, and non-residential properties were removed.\n\n✅ Narrative explaining decisions: rationale for each filtering and transformation step, including choices about time range (2023–2024), residential property type selection, treatment of missing or implausible values, and creation of derived variables such as house_age.\n\nTogether, these components ensure transparency and reproducibility of the data preprocessing workflow prior to modeling.\n\n---\n\n### Phase 2: Exploratory Data Analysis\n\n**Create at least 5 professional visualizations:**\n\n1. Distribution of sale prices (histogram)\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot(opa_census, aes(x = sale_price)) +\n  geom_histogram(bins = 40, fill = \"steelblue\", color = \"white\") +\n  geom_vline(aes(xintercept = median(log(sale_price))), linetype = \"dashed\") +\n  labs(title = \"Distribution of Log Sale Prices (2023–2024)\",\n       x = \"Sale Price\", y = \"Count\")\n```\n\n::: {.cell-output-display}\n![](Midterm_2025_files/figure-html/unnamed-chunk-7-1.png){width=672}\n:::\n:::\n\n\n2. Geographic distribution (map)\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot() +\n  geom_sf(data = philly_census, fill = \"lightgrey\", color = \"white\") +\n  geom_sf(data = opa_census, aes(color = sale_price), size = 0.1, alpha = 0.7) +\n  scale_color_viridis_c(option = \"plasma\") +\n  theme_minimal() +\n  labs(title = \"Housing Sales in Philadelphia (2023-2024)\", color = \"Sale Price\")\n```\n\n::: {.cell-output-display}\n![](Midterm_2025_files/figure-html/unnamed-chunk-8-1.png){width=672}\n:::\n:::\n\n\n3. Price vs. structural features (scatter plots)\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot(opa_census, aes(x = total_livable_area, y = sale_price)) +\n  geom_point(alpha = 0.3) +\n  geom_smooth(method = \"lm\", color = \"red\") +\n  scale_x_log10() +\n  labs(title = \"Sale Price vs. Livable Area\",\n       x = \"Total Livable Area \", y = \"Sale Price\")\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\n`geom_smooth()` using formula = 'y ~ x'\n```\n\n\n:::\n\n::: {.cell-output-display}\n![](Midterm_2025_files/figure-html/unnamed-chunk-9-1.png){width=672}\n:::\n:::\n\n\n4. Price vs. spatial features (scatter plots)\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot(opa_census, aes(x = unemployment_rate, y = sale_price)) +\n  geom_jitter(alpha = 0.3, color = \"#4682B4\") +\n  geom_smooth(method = \"lm\", se = FALSE, color = \"darkred\", linewidth = 0.8) +\n  scale_y_log10(labels = scales::dollar) +\n  labs(\n    title = \"Sale Price vs unemployment rate\",\n    x = \"unemployment rate (%)\",\n    y = \"Sale Price\"\n  )\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\n`geom_smooth()` using formula = 'y ~ x'\n```\n\n\n:::\n\n::: {.cell-output-display}\n![](Midterm_2025_files/figure-html/unnamed-chunk-10-1.png){width=672}\n:::\n:::\n\n\n5. One creative visualization\n\n::: {.cell}\n\n```{.r .cell-code}\nward_boundaries <- st_read(\"~/Datasets for r Trainning/Political_Wards.geojson\") %>%\n  st_transform(2272) %>%\n  mutate(\n    geographic_ward = as.character(ward_num)\n  )\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nReading layer `Political_Wards' from data source \n  `C:\\Users\\Jingqi\\Documents\\Datasets for r Trainning\\Political_Wards.geojson' \n  using driver `GeoJSON'\nSimple feature collection with 66 features and 4 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: -75.28031 ymin: 39.86748 xmax: -74.95574 ymax: 40.13793\nGeodetic CRS:  WGS 84\n```\n\n\n:::\n\n```{.r .cell-code}\nward_price <- opa_census %>%\n  st_drop_geometry() %>%\n  mutate(geographic_ward = as.character(geographic_ward)) %>%\n  group_by(geographic_ward) %>%\n  summarise(median_price = median(sale_price, na.rm = TRUE))\n\nward_sf <- ward_boundaries %>%\n  left_join(ward_price, by = \"geographic_ward\")\n\nggplot(ward_sf) +\n  geom_sf(aes(fill = median_price), color = \"white\", size = 0.2) +\n  scale_fill_viridis_c(option = \"plasma\", labels = scales::dollar) +\n  labs(\n    title = \"Median Residential Sale Price by Ward (2023–2024)\",\n    subtitle = \"Philadelphia, PA\",\n    caption = \"Data: OPA Property Sales 2023–2024\"\n  ) +\n  coord_sf(datum = NA) +\n  theme_minimal(base_size = 14) +\n  theme(\n    axis.text = element_blank(),\n    axis.ticks = element_blank(),\n    panel.grid = element_blank()\n  )\n```\n\n::: {.cell-output-display}\n![](Midterm_2025_files/figure-html/unnamed-chunk-11-1.png){width=672}\n:::\n:::\n\n\n\n**For presentation slides:** Select your **best 2-3 visualizations** that tell a compelling story\n\n**For appendix:** Include all visualizations with detailed interpretations\n\n**Example presentation slide:**\n\n```markdown\n## Where Are Expensive Homes in Philadelphia?\n\n[Beautiful map showing price patterns]\n\n**Key Findings:**\n- Center City and University City command premium prices\n- River wards show emerging appreciation\n- Northeast Philadelphia remains most affordable\n```\n\n---\n\n### Phase 3: Feature Engineering (Technical Appendix)\n\n**Create spatial features: (these are examples below, but how you construct your model is up to your team)**\n\n1. **Buffer-based features**:\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Load transit stop data and create buffer-based feature\nTransit <- read_csv(\"~/Datasets for r Trainning/Transit.csv\")\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nRows: 22478 Columns: 11\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (4): LineAbbr, Direction, StopAbbr, StopName\ndbl (7): X, Y, FID, Sequence, StopId, Lon, Lat\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n```\n\n\n:::\n\n```{.r .cell-code}\ntransit_sf <- st_as_sf(Transit, coords = c(\"Lon\", \"Lat\"), crs = 4326) %>%\n  st_transform(st_crs(opa_census))\nradius <- 400\nopa_census$transit_count <- lengths(st_is_within_distance(opa_census, transit_sf, dist = radius))\nread_csv(\"~/Datasets for r Trainning/Transit.csv\", show_col_types = FALSE)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 22,478 × 11\n           X        Y   FID LineAbbr Direction Sequence StopId StopAbbr StopName\n       <dbl>    <dbl> <dbl> <chr>    <chr>        <dbl>  <dbl> <chr>    <chr>   \n 1 -8364470. 4869338.     1 4        Northbou…       84  17382 9THWYONO 9th St …\n 2 -8364431. 4869570.     2 4        Northbou…       85  28692 9THLOUNO 9th St …\n 3 -8364395. 4869787.     3 4        Northbou…       86  17384 9THROCNO 9th St …\n 4 -8364358. 4870003.     4 4        Northbou…       87  17386 9THRUSNO 9th St …\n 5 -8364321. 4870222.     5 4        Northbou…       88  17387 9THLINNO 9th St …\n 6 -8364284. 4870445.     6 4        Northbou…       89  17389 9THDUNNO 9th St …\n 7 -8364248. 4870671.     7 4        Northbou…       90  17390 FIS9THWE 9th St …\n 8 -8364419. 4870722.     8 4        Northbou…       91  17393 FIS10TWE Fisher …\n 9 -8364534. 4870916.     9 4        Northbou…       92  28693 WAG10TNW 10th St…\n10 -8364559. 4870989.    10 4        Northbou…       93  17394 11TSOMNO 11th St…\n# ℹ 22,468 more rows\n# ℹ 2 more variables: Lon <dbl>, Lat <dbl>\n```\n\n\n:::\n:::\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nrecreation <- read_csv(\"~/Datasets for r Trainning/recreation.csv\") \n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nRows: 171 Columns: 12\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (7): PARK_NAME, PROGRAM_TYPE, SITE_CLASS, BUILDING, GYM, COMMENTS, DATA_...\ndbl (4): X, Y, OBJECTID, DPP_ASSET_ID\nlgl (1): LABEL_NUMBER\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n```\n\n\n:::\n\n```{.r .cell-code}\nrecreation_sf <- st_as_sf(recreation, coords = c(\"X\", \"Y\"), crs = 4326) %>% st_transform(st_crs(opa_census)) \nradius_rec <- 1200 \nopa_census$recreation_count <- lengths(st_is_within_distance(opa_census, recreation_sf, dist = radius_rec)) \nread_csv(\"~/Datasets for r Trainning/recreation.csv\", show_col_types = FALSE)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 171 × 12\n       X     Y OBJECTID PARK_NAME  DPP_ASSET_ID PROGRAM_TYPE SITE_CLASS BUILDING\n   <dbl> <dbl>    <dbl> <chr>             <dbl> <chr>        <chr>      <chr>   \n 1 -75.2  40.0      807 Tiffany F…         1911 PPR_REC      A          Y       \n 2 -75.2  40.0      808 Roberto C…         1831 PPR_REC      B          Y       \n 3 -75.2  40.0      809 Miles Mac…         1910 PPR_REC      A          Y       \n 4 -75.3  40.0      810 William T…         1864 PPR_REC      B          Y       \n 5 -75.2  40.0      811 Francisvi…         1859 PPR_REC      A          Y       \n 6 -75.3  40.0      812 Charles A…         1929 PPR_REC      A          Y       \n 7 -75.1  40.0      813 Fishtown …         1856 PPR_REC      A          Y       \n 8 -75.1  40.0      814 Narcissa …          908 PPR_REC      A          Y       \n 9 -75.2  40.0      815 Conestoga…         1982 PPR_REC      A          Y       \n10 -75.1  40.0      816 Dan Shiss…         1844 PPR_REC      A          Y       \n# ℹ 161 more rows\n# ℹ 4 more variables: GYM <chr>, LABEL_NUMBER <lgl>, COMMENTS <chr>,\n#   DATA_SOURCE <chr>\n```\n\n\n:::\n:::\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Load crime data and create buffer-based feature \ncrime <- read_csv(\"~/Datasets for r Trainning/crime.csv\") %>% \n  filter(!is.na(lat) & !is.na(lng)) \n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nRows: 169017 Columns: 18\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr  (6): the_geom, the_geom_webmercator, dc_dist, psa, location_block, text...\ndbl  (9): cartodb_id, objectid, hour, dc_key, ucr_general, point_x, point_y,...\ndttm (1): dispatch_date_time\ndate (1): dispatch_date\ntime (1): dispatch_time\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n```\n\n\n:::\n\n```{.r .cell-code}\ncrime_sf <- st_as_sf(crime, coords = c(\"lng\", \"lat\"), crs = 4326) %>%\n  st_transform(st_crs(opa_census)) \nradius_cri <- 400 \nopa_census$crime_count <- lengths(st_is_within_distance(opa_census, crime_sf, dist = radius_cri)) \nread_csv(\"~/Datasets for r Trainning/crime.csv\", show_col_types = FALSE)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 169,017 × 18\n   the_geom               cartodb_id the_geom_webmercator objectid dc_dist psa  \n   <chr>                       <dbl> <chr>                   <dbl> <chr>   <chr>\n 1 0101000020E61000002C3…      43806 0101000020110F0000F… 32951062 02      1    \n 2 0101000020E6100000905…      43828 0101000020110F00008… 32951072 17      1    \n 3 0101000020E6100000A4F…      43847 0101000020110F00002… 32951081 14      2    \n 4 0101000020E6100000A4F…      43848 0101000020110F00002… 32951082 14      2    \n 5 0101000020E6100000A4F…      43849 0101000020110F00002… 32951083 14      2    \n 6 0101000020E6100000241…      43850 0101000020110F0000B… 32951108 03      3    \n 7 0101000020E6100000580…      43905 0101000020110F00002… 32951093 12      4    \n 8 0101000020E6100000580…      43906 0101000020110F00002… 32951094 12      4    \n 9 0101000020E6100000580…      43908 0101000020110F00002… 32951095 12      4    \n10 0101000020E6100000580…      43911 0101000020110F00002… 32951096 12      4    \n# ℹ 169,007 more rows\n# ℹ 12 more variables: dispatch_date_time <dttm>, dispatch_date <date>,\n#   dispatch_time <time>, hour <dbl>, dc_key <dbl>, location_block <chr>,\n#   ucr_general <dbl>, text_general_code <chr>, point_x <dbl>, point_y <dbl>,\n#   lat <dbl>, lng <dbl>\n```\n\n\n:::\n:::\n\n\n2. **k-Nearest Neighbor features**:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nhospital_sf <- st_read(\"~/Datasets for r Trainning/hospitals.geojson\", quiet = TRUE) %>%\n  st_transform(st_crs(opa_census))\nopa_census <- st_transform(opa_census, st_crs(hospital_sf))\nnearest_hospital_index <- st_nearest_feature(opa_census, hospital_sf)\nopa_census$nearest_hospital_m <- st_distance(\n  opa_census,\n  hospital_sf[nearest_hospital_index, ],\n  by_element = TRUE\n)\nopa_census$nearest_hospital_m <- as.numeric(opa_census$nearest_hospital_m)\n```\n:::\n\n\n\n3. **Census variables**:\n\n   See secondary data above for examples (median income, education rate, unemployment rate, etc.)\n\n4. **Interaction terms**:\n\n   - Theoretically motivated combinations\n   - Example: `total_livable_area * house_age`\n\n**Deliverable (Appendix only):**\n\n- All feature engineering code\n- Summary table of features created\n- Brief justification for each feature\n\n::: {.cell}\n\n```{.r .cell-code}\nsummary_table <- opa_census %>%\n  st_drop_geometry() %>%\n  summarise(across(\n    where(is.numeric),\n    list(mean = ~mean(., na.rm = TRUE),\n         sd   = ~sd(., na.rm = TRUE),\n         min  = ~min(., na.rm = TRUE),\n         max  = ~max(., na.rm = TRUE))\n  )) %>%\n  pivot_longer(\n    cols = everything(),\n    names_to = c(\"variable\", \"stat\"),\n    names_pattern = \"^(.*)_(mean|sd|min|max)$\"\n  ) %>%\n  pivot_wider(\n    names_from = stat,\n    values_from = value\n  )\n\nprint(summary_table)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 33 × 5\n   variable                  mean         sd   min      max\n   <chr>                    <dbl>      <dbl> <dbl>    <dbl>\n 1 sale_price          339609.    458326.     1500 15428633\n 2 market_value        299951.    308680.     5000 14660000\n 3 total_livable_area    1368.       602.      120    14150\n 4 number_of_bedrooms       2.83       0.998     0       12\n 5 number_of_bathrooms      1.38       0.723     0       12\n 6 number_stories           1.96       0.585     1        5\n 7 garage_spaces            0.343      0.585     0       37\n 8 central_air              0.600      0.490     0        1\n 9 interior_condition       3.37       0.981     0        7\n10 exterior_condition       3.68       0.884     0        7\n# ℹ 23 more rows\n```\n\n\n:::\n:::\n\n\n---\n\n### Phase 4: Model Building\n\n**Build models progressively: (for example)**\n\n1. Structural features only\n\n::: {.cell}\n\n```{.r .cell-code}\nmodel1 <- lm(sale_price ~ total_livable_area + number_of_bedrooms +\n               number_of_bathrooms + house_age,\n             data = opa_census)\nsummary(model1)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nCall:\nlm(formula = sale_price ~ total_livable_area + number_of_bedrooms + \n    number_of_bathrooms + house_age, data = opa_census)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-3106972  -129059   -51002    34078 12819341 \n\nCoefficients:\n                      Estimate Std. Error t value Pr(>|t|)    \n(Intercept)          39619.855  12037.673   3.291 0.000999 ***\ntotal_livable_area     269.286      5.226  51.533  < 2e-16 ***\nnumber_of_bedrooms  -54370.943   3111.804 -17.472  < 2e-16 ***\nnumber_of_bathrooms 112256.591   4625.398  24.270  < 2e-16 ***\nhouse_age             -835.628     89.777  -9.308  < 2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 416200 on 25187 degrees of freedom\n  (918 observations deleted due to missingness)\nMultiple R-squared:  0.1904,\tAdjusted R-squared:  0.1903 \nF-statistic:  1481 on 4 and 25187 DF,  p-value: < 2.2e-16\n```\n\n\n:::\n:::\n\n\n2. + Census variables\n\n::: {.cell}\n\n```{.r .cell-code}\nmodel2 <- lm(sale_price ~ total_livable_area + number_of_bedrooms +\n               number_of_bathrooms + house_age +\n               median_income + ba_rate + unemployment_rate,\n             data = opa_census)\nsummary(model2)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nCall:\nlm(formula = sale_price ~ total_livable_area + number_of_bedrooms + \n    number_of_bathrooms + house_age + median_income + ba_rate + \n    unemployment_rate, data = opa_census)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-2746189  -108765   -43321    19441 12907761 \n\nCoefficients:\n                      Estimate Std. Error t value Pr(>|t|)    \n(Intercept)         -6.634e+04  1.560e+04  -4.253 2.12e-05 ***\ntotal_livable_area   2.480e+02  5.224e+00  47.473  < 2e-16 ***\nnumber_of_bedrooms  -2.708e+04  3.235e+03  -8.370  < 2e-16 ***\nnumber_of_bathrooms  7.618e+04  4.759e+03  16.009  < 2e-16 ***\nhouse_age           -7.569e+02  8.914e+01  -8.491  < 2e-16 ***\nmedian_income        2.517e-01  1.370e-01   1.837 0.066206 .  \nba_rate              5.027e+03  3.559e+02  14.126  < 2e-16 ***\nunemployment_rate   -2.033e+03  5.375e+02  -3.783 0.000156 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 410500 on 25184 degrees of freedom\n  (918 observations deleted due to missingness)\nMultiple R-squared:  0.2127,\tAdjusted R-squared:  0.2124 \nF-statistic: 971.7 on 7 and 25184 DF,  p-value: < 2.2e-16\n```\n\n\n:::\n:::\n\n\n3. + Spatial features\n\n::: {.cell}\n\n```{.r .cell-code}\nmodel3 <- lm(sale_price ~ total_livable_area + number_of_bedrooms +\n               number_of_bathrooms + house_age +\n               median_income + ba_rate + crime_count +\n               transit_count + recreation_count + nearest_hospital_m,\n             data = opa_census)\nsummary(model3)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nCall:\nlm(formula = sale_price ~ total_livable_area + number_of_bedrooms + \n    number_of_bathrooms + house_age + median_income + ba_rate + \n    crime_count + transit_count + recreation_count + nearest_hospital_m, \n    data = opa_census)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-2759832  -115652   -37521    35962 12612068 \n\nCoefficients:\n                      Estimate Std. Error t value Pr(>|t|)    \n(Intercept)         -1.822e+05  1.665e+04 -10.945  < 2e-16 ***\ntotal_livable_area   2.556e+02  5.198e+00  49.179  < 2e-16 ***\nnumber_of_bedrooms  -1.680e+04  3.242e+03  -5.181 2.22e-07 ***\nnumber_of_bathrooms  6.735e+04  4.738e+03  14.216  < 2e-16 ***\nhouse_age           -1.155e+03  9.096e+01 -12.700  < 2e-16 ***\nmedian_income        7.282e-01  1.343e-01   5.423 5.90e-08 ***\nba_rate              4.155e+03  3.636e+02  11.426  < 2e-16 ***\ncrime_count          1.361e+02  1.106e+01  12.302  < 2e-16 ***\ntransit_count        1.301e+03  1.382e+02   9.413  < 2e-16 ***\nrecreation_count    -8.122e+02  1.274e+03  -0.637    0.524    \nnearest_hospital_m  -2.059e+00  2.863e+00  -0.719    0.472    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 406700 on 25181 degrees of freedom\n  (918 observations deleted due to missingness)\nMultiple R-squared:  0.227,\tAdjusted R-squared:  0.2267 \nF-statistic: 739.4 on 10 and 25181 DF,  p-value: < 2.2e-16\n```\n\n\n:::\n:::\n\n\n4. + Interactions and fixed effects\n\n::: {.cell}\n\n```{.r .cell-code}\nward_boundaries <- st_transform(ward_boundaries, st_crs(opa_census))\nopa_census <- st_join(opa_census, ward_boundaries %>% dplyr::select(geographic_ward), left = TRUE)\n\nmodel4 <- lm(sale_price ~ total_livable_area * house_age +\n               number_of_bathrooms + house_age +\n               median_income + ba_rate + crime_count +\n               transit_count + nearest_hospital_m + factor(geographic_ward.y),\n             data = opa_census)\nsummary(model4)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nCall:\nlm(formula = sale_price ~ total_livable_area * house_age + number_of_bathrooms + \n    house_age + median_income + ba_rate + crime_count + transit_count + \n    nearest_hospital_m + factor(geographic_ward.y), data = opa_census)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-1356133  -108763   -25575    45039 11347614 \n\nCoefficients:\n                               Estimate Std. Error t value Pr(>|t|)    \n(Intercept)                  -2.453e+05  3.450e+04  -7.109 1.20e-12 ***\ntotal_livable_area            4.192e+02  9.866e+00  42.489  < 2e-16 ***\nhouse_age                     2.224e+03  1.931e+02  11.516  < 2e-16 ***\nnumber_of_bathrooms           4.054e+04  4.189e+03   9.677  < 2e-16 ***\nmedian_income                -3.155e-01  1.580e-01  -1.996 0.045900 *  \nba_rate                       2.104e+03  4.870e+02   4.320 1.56e-05 ***\ncrime_count                   3.260e+01  1.285e+01   2.537 0.011187 *  \ntransit_count                -2.174e+02  1.604e+02  -1.355 0.175303    \nnearest_hospital_m           -1.277e+01  5.442e+00  -2.347 0.018947 *  \nfactor(geographic_ward.y)10  -8.399e+04  3.208e+04  -2.618 0.008854 ** \nfactor(geographic_ward.y)11  -1.356e+05  3.755e+04  -3.610 0.000306 ***\nfactor(geographic_ward.y)12  -5.652e+04  3.262e+04  -1.733 0.083126 .  \nfactor(geographic_ward.y)13  -1.082e+05  3.337e+04  -3.243 0.001186 ** \nfactor(geographic_ward.y)14  -4.444e+04  6.467e+04  -0.687 0.492037    \nfactor(geographic_ward.y)15   1.300e+05  2.721e+04   4.779 1.77e-06 ***\nfactor(geographic_ward.y)16  -5.721e+04  3.360e+04  -1.703 0.088612 .  \nfactor(geographic_ward.y)17  -1.187e+05  3.475e+04  -3.415 0.000639 ***\nfactor(geographic_ward.y)18  -2.734e+04  2.700e+04  -1.013 0.311227    \nfactor(geographic_ward.y)19  -1.466e+05  3.583e+04  -4.092 4.29e-05 ***\nfactor(geographic_ward.y)2    1.119e+05  2.619e+04   4.274 1.92e-05 ***\nfactor(geographic_ward.y)20  -1.466e+05  5.748e+04  -2.550 0.010772 *  \nfactor(geographic_ward.y)21  -4.677e+04  2.351e+04  -1.989 0.046660 *  \nfactor(geographic_ward.y)22  -6.415e+04  3.186e+04  -2.014 0.044054 *  \nfactor(geographic_ward.y)23  -9.051e+04  3.210e+04  -2.819 0.004816 ** \nfactor(geographic_ward.y)24  -7.628e+04  4.171e+04  -1.829 0.067484 .  \nfactor(geographic_ward.y)25  -3.169e+04  2.815e+04  -1.126 0.260174    \nfactor(geographic_ward.y)26  -5.375e+04  3.038e+04  -1.770 0.076808 .  \nfactor(geographic_ward.y)27  -1.286e+04  4.740e+04  -0.271 0.786181    \nfactor(geographic_ward.y)28  -1.482e+05  3.507e+04  -4.226 2.39e-05 ***\nfactor(geographic_ward.y)29  -6.366e+04  3.200e+04  -1.989 0.046695 *  \nfactor(geographic_ward.y)3   -3.813e+04  3.370e+04  -1.131 0.257857    \nfactor(geographic_ward.y)30   2.050e+05  2.727e+04   7.519 5.72e-14 ***\nfactor(geographic_ward.y)31   4.883e+03  2.505e+04   0.195 0.845441    \nfactor(geographic_ward.y)32   1.317e+04  3.311e+04   0.398 0.690895    \nfactor(geographic_ward.y)33  -1.382e+05  3.004e+04  -4.600 4.24e-06 ***\nfactor(geographic_ward.y)34   5.623e+04  2.863e+04   1.964 0.049578 *  \nfactor(geographic_ward.y)35  -9.356e+04  2.919e+04  -3.206 0.001349 ** \nfactor(geographic_ward.y)36  -5.053e+04  2.405e+04  -2.100 0.035695 *  \nfactor(geographic_ward.y)37  -2.155e+05  4.203e+04  -5.127 2.96e-07 ***\nfactor(geographic_ward.y)38  -1.808e+04  2.938e+04  -0.615 0.538305    \nfactor(geographic_ward.y)39  -1.733e+04  2.442e+04  -0.710 0.477864    \nfactor(geographic_ward.y)4    1.514e+05  3.225e+04   4.696 2.67e-06 ***\nfactor(geographic_ward.y)40  -5.833e+04  2.791e+04  -2.090 0.036624 *  \nfactor(geographic_ward.y)41  -7.278e+04  3.128e+04  -2.327 0.019982 *  \nfactor(geographic_ward.y)42  -7.694e+04  2.960e+04  -2.600 0.009334 ** \nfactor(geographic_ward.y)43  -4.740e+03  3.118e+04  -0.152 0.879177    \nfactor(geographic_ward.y)44   3.362e+04  3.494e+04   0.962 0.335917    \nfactor(geographic_ward.y)45  -2.019e+04  2.848e+04  -0.709 0.478421    \nfactor(geographic_ward.y)46  -2.948e+04  3.371e+04  -0.874 0.381869    \nfactor(geographic_ward.y)47   5.153e+04  6.149e+04   0.838 0.402019    \nfactor(geographic_ward.y)48  -6.535e+04  3.007e+04  -2.173 0.029784 *  \nfactor(geographic_ward.y)49  -9.946e+04  3.364e+04  -2.957 0.003113 ** \nfactor(geographic_ward.y)5    1.311e+05  2.446e+04   5.358 8.51e-08 ***\nfactor(geographic_ward.y)50  -5.237e+04  3.419e+04  -1.532 0.125627    \nfactor(geographic_ward.y)51  -5.723e+04  3.107e+04  -1.842 0.065482 .  \nfactor(geographic_ward.y)52  -1.220e+05  3.321e+04  -3.673 0.000241 ***\nfactor(geographic_ward.y)53  -9.117e+04  3.079e+04  -2.961 0.003073 ** \nfactor(geographic_ward.y)54  -5.779e+04  3.130e+04  -1.847 0.064821 .  \nfactor(geographic_ward.y)55  -5.140e+04  2.899e+04  -1.773 0.076239 .  \nfactor(geographic_ward.y)56  -4.129e+04  2.883e+04  -1.433 0.152010    \nfactor(geographic_ward.y)57  -4.913e+04  2.916e+04  -1.685 0.092001 .  \nfactor(geographic_ward.y)58  -8.691e+03  2.974e+04  -0.292 0.770134    \nfactor(geographic_ward.y)59  -1.688e+04  3.467e+04  -0.487 0.626295    \nfactor(geographic_ward.y)6   -1.429e+05  4.237e+04  -3.372 0.000748 ***\nfactor(geographic_ward.y)60   4.077e+04  3.497e+04   1.166 0.243589    \nfactor(geographic_ward.y)61  -1.200e+05  3.114e+04  -3.853 0.000117 ***\nfactor(geographic_ward.y)62  -7.175e+04  2.951e+04  -2.432 0.015042 *  \nfactor(geographic_ward.y)63  -2.766e+04  3.000e+04  -0.922 0.356543    \nfactor(geographic_ward.y)64  -4.970e+04  3.248e+04  -1.530 0.126006    \nfactor(geographic_ward.y)65  -5.590e+04  2.913e+04  -1.919 0.055026 .  \nfactor(geographic_ward.y)66  -2.391e+04  2.590e+04  -0.923 0.355869    \nfactor(geographic_ward.y)7   -1.021e+05  3.148e+04  -3.245 0.001176 ** \nfactor(geographic_ward.y)8    4.994e+05  2.701e+04  18.488  < 2e-16 ***\nfactor(geographic_ward.y)9    2.249e+05  3.239e+04   6.942 3.97e-12 ***\ntotal_livable_area:house_age -2.042e+00  9.944e-02 -20.536  < 2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 394500 on 25119 degrees of freedom\n  (916 observations deleted due to missingness)\nMultiple R-squared:  0.2744,\tAdjusted R-squared:  0.2723 \nF-statistic: 128.4 on 74 and 25119 DF,  p-value: < 2.2e-16\n```\n\n\n:::\n:::\n\n\n\n**For presentation slides:** Show **one comparison table** (RMSE, R² for 4 different models you constructed in your process)\n\n**For appendix:**\n\n- Complete model code\n- Full stargazer/modelsummary output\n- Coefficient interpretations\n\n**Example presentation slide:**\n\n```markdown\n## Model Performance Improves with Each Layer\n\n| Model | CV RMSE (log) | R² |\n|-------|---------------|-----|\n| Structural Only | 0.42 | 0.61 |\n| + Census | 0.38 | 0.69 |\n| + Spatial | 0.31 | 0.78 |\n| + Interactions/FE | 0.26 | 0.84 |\n\n**Bottom line:** Neighborhood effects matter most!\n```\n\n---\n\n### Phase 5: Model Validation\n\n**Use 10-fold cross-validation:**\n- Compare all 4 models\n- Report RMSE, MAE, R² for each\n- Create predicted vs. actual plot\n\n::: {.cell}\n\n```{.r .cell-code}\nmodel_data <- opa_census %>%\n  st_drop_geometry() %>%\n  dplyr::select(\n    sale_price, total_livable_area, number_of_bedrooms,\n    number_of_bathrooms, house_age,\n    median_income, ba_rate, unemployment_rate,\n    crime_count, transit_count, recreation_count,\n    nearest_hospital_m, geographic_ward.y\n  ) %>%\n  filter(complete.cases(.))\n```\n:::\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nset.seed(42)\n\ncv_control <- trainControl(\n  method = \"cv\",\n  number = 10,\n  savePredictions = \"final\"\n)\n```\n:::\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nfml1 <- sale_price ~ total_livable_area + number_of_bedrooms + number_of_bathrooms + house_age\nfml2 <- update(fml1, . ~ . + median_income + ba_rate + unemployment_rate)\nfml3 <- update(fml2, . ~ . + crime_count + transit_count + recreation_count + nearest_hospital_m)\nfml4 <- update(fml3, . ~ . + total_livable_area:house_age + factor(geographic_ward.y))\n\nm1 <- train(fml1, data = model_data, method = \"lm\", trControl = cv_control)\nm2 <- train(fml2, data = model_data, method = \"lm\", trControl = cv_control)\nm3 <- train(fml3, data = model_data, method = \"lm\", trControl = cv_control)\nm4 <- train(fml4, data = model_data, method = \"lm\", trControl = cv_control)\n```\n:::\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nresults <- resamples(list(\n  Model1 = m1, Model2 = m2, Model3 = m3, Model4 = m4\n))\n\nsummary(results)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nCall:\nsummary.resamples(object = results)\n\nModels: Model1, Model2, Model3, Model4 \nNumber of resamples: 10 \n\nMAE \n           Min.  1st Qu.   Median     Mean  3rd Qu.     Max. NA's\nModel1 152235.1 157737.0 162730.0 162369.5 167572.4 169991.7    0\nModel2 126660.3 136852.3 141913.9 142058.1 146846.3 162193.6    0\nModel3 139271.6 142654.1 146708.2 147768.2 150881.0 160161.4    0\nModel4 135988.0 143534.9 145708.1 146378.5 147016.3 156004.2    0\n\nRMSE \n           Min.  1st Qu.   Median     Mean  3rd Qu.     Max. NA's\nModel1 366393.5 400504.9 419489.5 415452.1 428061.4 470111.9    0\nModel2 310999.8 356390.6 418042.2 406309.6 429887.7 512243.7    0\nModel3 338229.7 378669.6 387665.0 404616.0 425914.7 499001.2    0\nModel4 354668.1 378112.8 388187.7 394980.0 397163.2 446983.3    0\n\nRsquared \n            Min.   1st Qu.    Median      Mean   3rd Qu.      Max. NA's\nModel1 0.1199934 0.1606408 0.2023288 0.1932075 0.2188695 0.2660367    0\nModel2 0.1083257 0.2073197 0.2294594 0.2225998 0.2606119 0.3000572    0\nModel3 0.1616538 0.1930158 0.2213475 0.2319998 0.2636017 0.3328444    0\nModel4 0.1981433 0.2348501 0.2647516 0.2688002 0.3027461 0.3527661    0\n```\n\n\n:::\n:::\n\n\n::: {.cell}\n\n```{.r .cell-code}\npredicted_df <- m4$pred\nggplot(predicted_df, aes(x = pred, y = obs)) +\n  geom_point(alpha = 0.3, color = \"#4682B4\") +\n  geom_abline(slope = 1, intercept = 0, linetype = \"dashed\", color = \"red\") +\n  labs(title = \"Predicted vs. Actual Sale Prices (Model 4)\",\n       x = \"Predicted Price\", y = \"Actual Price\") +\n  theme_minimal()\n```\n\n::: {.cell-output-display}\n![](Midterm_2025_files/figure-html/unnamed-chunk-25-1.png){width=672}\n:::\n:::\n\n\n**For presentation slides:** Final CV results table (shown above) + one compelling visual\n\n**For appendix:** \n\n- Complete CV code\n- Detailed results\n- Predicted vs. actual scatter plot\n- Discussion of which features matter most\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(tibble)\nlibrary(gt)\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nWarning: package 'gt' was built under R version 4.4.3\n```\n\n\n:::\n\n```{.r .cell-code}\nmodel_results <- tibble(\n  Model = c(\"Model 1\", \"Model 2\", \"Model 3\", \"Model 4\"),\n  MAE = c(139645, 125333, 130631, 126322),\n  RMSE = c(348642, 344890, 341023, 326913),\n  R2 = c(0.304, 0.325, 0.341, 0.394)\n)\n\nmodel_results %>%\n  gt() %>%\n  fmt_number(columns = c(MAE, RMSE), decimals = 0) %>%\n  fmt_number(columns = R2, decimals = 3)\n```\n\n::: {.cell-output-display}\n\n```{=html}\n<div id=\"pdkpbjvqmg\" style=\"padding-left:0px;padding-right:0px;padding-top:10px;padding-bottom:10px;overflow-x:auto;overflow-y:auto;width:auto;height:auto;\">\n<style>#pdkpbjvqmg table {\n  font-family: system-ui, 'Segoe UI', Roboto, Helvetica, Arial, sans-serif, 'Apple Color Emoji', 'Segoe UI Emoji', 'Segoe UI Symbol', 'Noto Color Emoji';\n  -webkit-font-smoothing: antialiased;\n  -moz-osx-font-smoothing: grayscale;\n}\n\n#pdkpbjvqmg thead, #pdkpbjvqmg tbody, #pdkpbjvqmg tfoot, #pdkpbjvqmg tr, #pdkpbjvqmg td, #pdkpbjvqmg th {\n  border-style: none;\n}\n\n#pdkpbjvqmg p {\n  margin: 0;\n  padding: 0;\n}\n\n#pdkpbjvqmg .gt_table {\n  display: table;\n  border-collapse: collapse;\n  line-height: normal;\n  margin-left: auto;\n  margin-right: auto;\n  color: #333333;\n  font-size: 16px;\n  font-weight: normal;\n  font-style: normal;\n  background-color: #FFFFFF;\n  width: auto;\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #A8A8A8;\n  border-right-style: none;\n  border-right-width: 2px;\n  border-right-color: #D3D3D3;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #A8A8A8;\n  border-left-style: none;\n  border-left-width: 2px;\n  border-left-color: #D3D3D3;\n}\n\n#pdkpbjvqmg .gt_caption {\n  padding-top: 4px;\n  padding-bottom: 4px;\n}\n\n#pdkpbjvqmg .gt_title {\n  color: #333333;\n  font-size: 125%;\n  font-weight: initial;\n  padding-top: 4px;\n  padding-bottom: 4px;\n  padding-left: 5px;\n  padding-right: 5px;\n  border-bottom-color: #FFFFFF;\n  border-bottom-width: 0;\n}\n\n#pdkpbjvqmg .gt_subtitle {\n  color: #333333;\n  font-size: 85%;\n  font-weight: initial;\n  padding-top: 3px;\n  padding-bottom: 5px;\n  padding-left: 5px;\n  padding-right: 5px;\n  border-top-color: #FFFFFF;\n  border-top-width: 0;\n}\n\n#pdkpbjvqmg .gt_heading {\n  background-color: #FFFFFF;\n  text-align: center;\n  border-bottom-color: #FFFFFF;\n  border-left-style: none;\n  border-left-width: 1px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 1px;\n  border-right-color: #D3D3D3;\n}\n\n#pdkpbjvqmg .gt_bottom_border {\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n}\n\n#pdkpbjvqmg .gt_col_headings {\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #D3D3D3;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  border-left-style: none;\n  border-left-width: 1px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 1px;\n  border-right-color: #D3D3D3;\n}\n\n#pdkpbjvqmg .gt_col_heading {\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: normal;\n  text-transform: inherit;\n  border-left-style: none;\n  border-left-width: 1px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 1px;\n  border-right-color: #D3D3D3;\n  vertical-align: bottom;\n  padding-top: 5px;\n  padding-bottom: 6px;\n  padding-left: 5px;\n  padding-right: 5px;\n  overflow-x: hidden;\n}\n\n#pdkpbjvqmg .gt_column_spanner_outer {\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: normal;\n  text-transform: inherit;\n  padding-top: 0;\n  padding-bottom: 0;\n  padding-left: 4px;\n  padding-right: 4px;\n}\n\n#pdkpbjvqmg .gt_column_spanner_outer:first-child {\n  padding-left: 0;\n}\n\n#pdkpbjvqmg .gt_column_spanner_outer:last-child {\n  padding-right: 0;\n}\n\n#pdkpbjvqmg .gt_column_spanner {\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  vertical-align: bottom;\n  padding-top: 5px;\n  padding-bottom: 5px;\n  overflow-x: hidden;\n  display: inline-block;\n  width: 100%;\n}\n\n#pdkpbjvqmg .gt_spanner_row {\n  border-bottom-style: hidden;\n}\n\n#pdkpbjvqmg .gt_group_heading {\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: initial;\n  text-transform: inherit;\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #D3D3D3;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  border-left-style: none;\n  border-left-width: 1px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 1px;\n  border-right-color: #D3D3D3;\n  vertical-align: middle;\n  text-align: left;\n}\n\n#pdkpbjvqmg .gt_empty_group_heading {\n  padding: 0.5px;\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: initial;\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #D3D3D3;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  vertical-align: middle;\n}\n\n#pdkpbjvqmg .gt_from_md > :first-child {\n  margin-top: 0;\n}\n\n#pdkpbjvqmg .gt_from_md > :last-child {\n  margin-bottom: 0;\n}\n\n#pdkpbjvqmg .gt_row {\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n  margin: 10px;\n  border-top-style: solid;\n  border-top-width: 1px;\n  border-top-color: #D3D3D3;\n  border-left-style: none;\n  border-left-width: 1px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 1px;\n  border-right-color: #D3D3D3;\n  vertical-align: middle;\n  overflow-x: hidden;\n}\n\n#pdkpbjvqmg .gt_stub {\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: initial;\n  text-transform: inherit;\n  border-right-style: solid;\n  border-right-width: 2px;\n  border-right-color: #D3D3D3;\n  padding-left: 5px;\n  padding-right: 5px;\n}\n\n#pdkpbjvqmg .gt_stub_row_group {\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: initial;\n  text-transform: inherit;\n  border-right-style: solid;\n  border-right-width: 2px;\n  border-right-color: #D3D3D3;\n  padding-left: 5px;\n  padding-right: 5px;\n  vertical-align: top;\n}\n\n#pdkpbjvqmg .gt_row_group_first td {\n  border-top-width: 2px;\n}\n\n#pdkpbjvqmg .gt_row_group_first th {\n  border-top-width: 2px;\n}\n\n#pdkpbjvqmg .gt_summary_row {\n  color: #333333;\n  background-color: #FFFFFF;\n  text-transform: inherit;\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n}\n\n#pdkpbjvqmg .gt_first_summary_row {\n  border-top-style: solid;\n  border-top-color: #D3D3D3;\n}\n\n#pdkpbjvqmg .gt_first_summary_row.thick {\n  border-top-width: 2px;\n}\n\n#pdkpbjvqmg .gt_last_summary_row {\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n}\n\n#pdkpbjvqmg .gt_grand_summary_row {\n  color: #333333;\n  background-color: #FFFFFF;\n  text-transform: inherit;\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n}\n\n#pdkpbjvqmg .gt_first_grand_summary_row {\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n  border-top-style: double;\n  border-top-width: 6px;\n  border-top-color: #D3D3D3;\n}\n\n#pdkpbjvqmg .gt_last_grand_summary_row_top {\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n  border-bottom-style: double;\n  border-bottom-width: 6px;\n  border-bottom-color: #D3D3D3;\n}\n\n#pdkpbjvqmg .gt_striped {\n  background-color: rgba(128, 128, 128, 0.05);\n}\n\n#pdkpbjvqmg .gt_table_body {\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #D3D3D3;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n}\n\n#pdkpbjvqmg .gt_footnotes {\n  color: #333333;\n  background-color: #FFFFFF;\n  border-bottom-style: none;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  border-left-style: none;\n  border-left-width: 2px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 2px;\n  border-right-color: #D3D3D3;\n}\n\n#pdkpbjvqmg .gt_footnote {\n  margin: 0px;\n  font-size: 90%;\n  padding-top: 4px;\n  padding-bottom: 4px;\n  padding-left: 5px;\n  padding-right: 5px;\n}\n\n#pdkpbjvqmg .gt_sourcenotes {\n  color: #333333;\n  background-color: #FFFFFF;\n  border-bottom-style: none;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  border-left-style: none;\n  border-left-width: 2px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 2px;\n  border-right-color: #D3D3D3;\n}\n\n#pdkpbjvqmg .gt_sourcenote {\n  font-size: 90%;\n  padding-top: 4px;\n  padding-bottom: 4px;\n  padding-left: 5px;\n  padding-right: 5px;\n}\n\n#pdkpbjvqmg .gt_left {\n  text-align: left;\n}\n\n#pdkpbjvqmg .gt_center {\n  text-align: center;\n}\n\n#pdkpbjvqmg .gt_right {\n  text-align: right;\n  font-variant-numeric: tabular-nums;\n}\n\n#pdkpbjvqmg .gt_font_normal {\n  font-weight: normal;\n}\n\n#pdkpbjvqmg .gt_font_bold {\n  font-weight: bold;\n}\n\n#pdkpbjvqmg .gt_font_italic {\n  font-style: italic;\n}\n\n#pdkpbjvqmg .gt_super {\n  font-size: 65%;\n}\n\n#pdkpbjvqmg .gt_footnote_marks {\n  font-size: 75%;\n  vertical-align: 0.4em;\n  position: initial;\n}\n\n#pdkpbjvqmg .gt_asterisk {\n  font-size: 100%;\n  vertical-align: 0;\n}\n\n#pdkpbjvqmg .gt_indent_1 {\n  text-indent: 5px;\n}\n\n#pdkpbjvqmg .gt_indent_2 {\n  text-indent: 10px;\n}\n\n#pdkpbjvqmg .gt_indent_3 {\n  text-indent: 15px;\n}\n\n#pdkpbjvqmg .gt_indent_4 {\n  text-indent: 20px;\n}\n\n#pdkpbjvqmg .gt_indent_5 {\n  text-indent: 25px;\n}\n\n#pdkpbjvqmg .katex-display {\n  display: inline-flex !important;\n  margin-bottom: 0.75em !important;\n}\n\n#pdkpbjvqmg div.Reactable > div.rt-table > div.rt-thead > div.rt-tr.rt-tr-group-header > div.rt-th-group:after {\n  height: 0px !important;\n}\n</style>\n<table class=\"gt_table\" data-quarto-disable-processing=\"false\" data-quarto-bootstrap=\"false\">\n  <thead>\n    <tr class=\"gt_col_headings\">\n      <th class=\"gt_col_heading gt_columns_bottom_border gt_left\" rowspan=\"1\" colspan=\"1\" scope=\"col\" id=\"Model\">Model</th>\n      <th class=\"gt_col_heading gt_columns_bottom_border gt_right\" rowspan=\"1\" colspan=\"1\" scope=\"col\" id=\"MAE\">MAE</th>\n      <th class=\"gt_col_heading gt_columns_bottom_border gt_right\" rowspan=\"1\" colspan=\"1\" scope=\"col\" id=\"RMSE\">RMSE</th>\n      <th class=\"gt_col_heading gt_columns_bottom_border gt_right\" rowspan=\"1\" colspan=\"1\" scope=\"col\" id=\"R2\">R2</th>\n    </tr>\n  </thead>\n  <tbody class=\"gt_table_body\">\n    <tr><td headers=\"Model\" class=\"gt_row gt_left\">Model 1</td>\n<td headers=\"MAE\" class=\"gt_row gt_right\">139,645</td>\n<td headers=\"RMSE\" class=\"gt_row gt_right\">348,642</td>\n<td headers=\"R2\" class=\"gt_row gt_right\">0.304</td></tr>\n    <tr><td headers=\"Model\" class=\"gt_row gt_left\">Model 2</td>\n<td headers=\"MAE\" class=\"gt_row gt_right\">125,333</td>\n<td headers=\"RMSE\" class=\"gt_row gt_right\">344,890</td>\n<td headers=\"R2\" class=\"gt_row gt_right\">0.325</td></tr>\n    <tr><td headers=\"Model\" class=\"gt_row gt_left\">Model 3</td>\n<td headers=\"MAE\" class=\"gt_row gt_right\">130,631</td>\n<td headers=\"RMSE\" class=\"gt_row gt_right\">341,023</td>\n<td headers=\"R2\" class=\"gt_row gt_right\">0.341</td></tr>\n    <tr><td headers=\"Model\" class=\"gt_row gt_left\">Model 4</td>\n<td headers=\"MAE\" class=\"gt_row gt_right\">126,322</td>\n<td headers=\"RMSE\" class=\"gt_row gt_right\">326,913</td>\n<td headers=\"R2\" class=\"gt_row gt_right\">0.394</td></tr>\n  </tbody>\n  \n</table>\n</div>\n```\n\n:::\n:::\n\n\n\n---\n\n### Phase 6: Model Diagnostics (Technical Appendix Only)\n\n**Check assumptions for best model:**\n\n- Residual plot (linearity, homoscedasticity)\n- Q-Q plot (normality)\n- Cook's distance (influential observations)\n\n::: {.cell}\n\n```{.r .cell-code}\npar(mfrow = c(1, 3))\n\n# 1. Residuals vs Fitted\nplot(model4, which = 1, main = \"Residuals vs Fitted\")\n\n# 2. Normal Q-Q\nplot(model4, which = 2, main = \"Q-Q Plot\")\n\n# 3. Cook’s distance\nplot(model4, which = 4, main = \"Cook’s Distance\")\n```\n\n::: {.cell-output-display}\n![](Midterm_2025_files/figure-html/unnamed-chunk-27-1.png){width=672}\n:::\n:::\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nopa_census$predicted <- predict(model4, newdata = opa_census)\nopa_census$residual <- opa_census$sale_price - opa_census$predicted\n\nopa_census %>%\n  filter(!is.na(residual)) %>%\n  ggplot() +\n  geom_sf(aes(fill = residual), color = NA) +\n  scale_fill_gradient2(low = \"blue\", mid = \"white\", high = \"red\") +\n  labs(\n    title = \"Prediction Residuals (Model 4)\",\n    fill = \"Residual ($)\"\n  ) +\n  theme_minimal()\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nWarning: Removed 25194 rows containing missing values or values outside the scale range\n(`geom_sf()`).\n```\n\n\n:::\n\n::: {.cell-output-display}\n![](Midterm_2025_files/figure-html/unnamed-chunk-28-1.png){width=672}\n:::\n:::\n\n\n**Deliverable (Appendix only):**\n\n- All 3 diagnostic plots\n- Interpretation of each\n- How you addressed violations (if any)\n\n**Note:** Don't include diagnostic plots in presentation - too technical!\n\n---\n\n### Phase 7: Conclusions & Recommendations\n\n**Answer these questions:**\n\n1. What is your final model's accuracy?\n2. Which features matter most for Philadelphia prices?\n3. Which neighborhoods are hardest to predict?\n4. Equity concerns?\n5. Limitations?\n\n**For presentation slides:** 1-2 slides with clear, concise answers (bullet points)\n\n**For appendix:** 2-3 paragraphs with detailed discussion\n\n**Example presentation slide:**\n\n```markdown\n## Key Findings & Recommendations\n\n**Model Accuracy:** RMSE = 0.26 (log scale) ≈ 26% typical error\n\n**Top Predictors:**\n- Neighborhood fixed effects (largest impact)\n- Square footage (β = 0.0003, p < 0.001)\n- Distance to transit (β = -0.05, p < 0.001)\n\n**Recommendations:**\n✓ Current AVM undervalues transit-accessible properties  \n✓ Model struggles in rapidly gentrifying neighborhoods  \n```\n\n---\n\n## Submission Requirements\n\n### What to Submit (by 9:59 AM, October 27, 2025)\n\n**Upload to Canvas - A link to your portfolio that Contains**\n\n1. **Presentation Slides**\n\n   - `LastName_FirstName_Presentation.html` (rendered slides)\n   - `LastName_FirstName_Presentation.qmd` (source file)\n   - Must use `format: revealjs`\n   - 10-15 slides maximum\n   - No code visible in slides\n\n2. **Technical Appendix**\n\n   - `LastName_FirstName_Appendix.html` (rendered document)\n   - `LastName_FirstName_Appendix.qmd` (source file)\n   - Must use `format: html`\n   - All code visible and commented\n   - Complete analysis documented\n\n3. **Data files** OR clear download instructions in appendix\n\n**For Teams:** Use `LastName1_LastName2_Presentation.html`\n\n### In-Class Presentation (October 27, 2025)\n\n**Format:** 5 minutes per team\n\n**What to present:**\n\n- Walk through your presentation slides. Choose your team's spoke's person or take turns You'll all stand up there and try to look calm, confident, & collected.\n- Hit the highlights - research question, key viz, model results, recommendations\n- Speak to a policy audience (your classmates are pretending to be city officials)\n- Be ready for 1-2 questions\n- You are trying to win the bid! Convince the audience of your agency's work.\n\n**What NOT to do:**\n\n- Don't read slides verbatim\n- Don't show code\n- Don't go into technical details\n- Don't go over 5 minutes (I'll cut you off!)\n\n---\n\n## Grading Rubric (Scaled to 15% of course grade)\n\n### Presentation Slides \n\n| Component | Points | Criteria |\n|-----------|--------|----------|\n| **Research Question** | 2 | Clear motivation, Set the stage |\n| **Data Overview** | 2 | Concise description of sources, sample size |\n| **Visualizations** | 3 | 2-3 polished, publication-quality visualizations; clear takeaways |\n| **Model Comparison** | 3 | Clean results table; clear winner; interprets improvement |\n| **Key Findings** | 3 | Top predictors identified; coefficients interpreted correctly |\n| **Presentation Quality** | 3 | Professional design, no typos, flows logically, appropriate for audience |\n\n**Key:** Slides should tell a compelling story without technical jargon. Imagine presenting to the Deputy Mayor.\n\n---\n\n### In-Class Presentation\n\n| Component | Points | Criteria |\n|-----------|--------|----------|\n| **Content** | 2 | Covers key points efficiently, answers questions thoughtfully |\n| **Time Management** | 2 | Finishes within 5 minutes without rushing |\n\n---\n\n### Technical Appendix \n\n| Component | Points | Criteria |\n|-----------|--------|----------|\n| **Data Cleaning** | 3 | Complete code, proper filtering, missing value handling, documentation |\n| **EDA** | 3 | 5+ visualizations, each with interpretation |\n| **Feature Engineering** | 3 | Buffers , kNN , census , interactions , all properly created |\n| **Model Building** | 3 | 4 progressive models, proper specification, handles sparse categories |\n| **Cross-Validation** | 3 | Proper 10-fold CV, results table, code runs without errors |\n| **Diagnostics** | 3 | Residual plots included, interpreted, violations addressed |\n| **Code Quality** | 3 | Clean, commented, reproducible, follows best practices, no errors |\n\n**Key:** This is where technical reviewers verify your work. All code must run without errors & be reproducible!!.\n\n---\n\n\n## Example Presentation Structure\n\n**Slide 1: Title**\n- Your team name and teammates\n- Project title\n- Date\n\n**Slide 2: The Problem**\n\n\n**Slide 3: Data Sources**\n- Property sales (n = X,XXX, 2023-2024)\n- Census ACS (income, education, poverty)\n- OpenDataPhilly (parks, transit, crime)\n\n**Slide 4: Where Are Expensive Homes?**\n- [Map visualization]\n- Key pattern observed\n\n**Slide 5: What Drives Prices?**\n- [Best scatter plot or faceted visualization]\n- Key relationship identified\n\n**Slide 6: Model Comparison**\n- [Results table]\n- \"Each layer improves prediction\"\n\n**Slide 7: Top Predictors**\n- Neighborhood (biggest impact)\n- Square footage (β = X)\n- Transit access (β = Y)\n\n**Slide 8: Model Performance**\n- Final RMSE: 0.26 (log scale)\n- Translation: ~26% typical error\n- Beats baseline by 40%\n\n**Slide 9: Hardest to Predict**\n- [Visualization of residuals by neighborhood]\n\n\n**Slide 10: Recommendations**\n\n\n**Slide 11: Limitations & Next Steps**\n\n\n**Slide 12: Questions?**\n- Thank you\n- [Contact info]\n\n---\n\n## Tips for Success\n\n### Start Early\n- Data cleaning always takes longer than expected\n- OpenDataPhilly can be slow to download\n- Leave time for troubleshooting AND RENDERING!!!\n\n### Check Your Work\n\n- Organize your file directory from the beginning. \n- Run your entire .qmd file from scratch before submitting \n- Make sure all visualizations display\n- Check that your narrative flows logically\n\n\n\n---\n\n## Frequently Asked Questions\n\n**Q: Do I have to create both slides AND an appendix?**  \n\nA: Yes! Slides are your main deliverable (present findings). Appendix proves you did the work correctly.\n\n**Q: Can code appear in my presentation slides?** \n\nA: NO! Slides are for city officials. All code goes in the technical appendix.\n\n**Q: How many slides should I have?**  \n\nA: 10-15 maximum. Quality over quantity. Each slide should have a clear purpose.\n\n**Q: Can I use a different city?**  \nA: No, everyone uses Philadelphia for comparability.\n\n**Q: How do I make my .qmd render as revealjs slides?**  \nA: Use `format: revealjs` in your YAML (see template above). Test it early!\n\n**Q: My presentation is 8 minutes. Is that okay?**  \nA: NO! You must cut it to 5 minutes. Practice and trim ruthlessly.\n\n**Q: Should I include all 5 EDA visualizations in my slides?**  \nA: No! Slides should have your best 2-3 visualizations. Put all 5 in the appendix.\n\n**Q: My RMSE is 0.35 in log scale. Is that good?**  \nA: Depends on your data, but 0.25-0.45 is typical for hedonic models. Compare to your baseline or put your data back into dollars!\n\n**Q: Should I remove all outliers?**  \nA: No! Only remove obvious errors. Use log transformation to handle legitimate outliers.\n\n**Q: What if my code works on my computer but not when I knit?**  \nA: Start fresh, restart R, knit in a clean session. Check for hard-coded paths.\n\n**Q: Can I use ChatGPT/Claude to write my analysis?**  \nA: You may use AI for debugging code, but NOT for writing your analysis. \n\n**Q: How formal should my presentation be?**  \nA: Professional but not stuffy. Like you're briefing a city council member who's smart but doesn't know statistics.\n\n**Q: What happens if I go over 5 minutes?**  \nA: I'll politely cut you off and you'll lose points. Practice with a timer!\n\n---\n\n## Example Workflow\n\n**Week 1:**\n- Download data\n- Initial cleaning\n- Basic EDA\n\n**Week 2:**\n- Feature engineering\n- Build 4 models\n- Run cross-validation\n- Diagnostics\n- Write conclusions\n- Proofread and submit\n\n---\n\n## Academic Integrity\n\n- You may discuss concepts with classmates\n- You may NOT share code or slides\n- All work must be your own (or your teams)\n- Cite any external resources used\n- Please acknowledge how you used AI in your work and which AI you used (For example, Claude helped me today in coming up with a draft of this assignment, but I edited it thoroughly!)\n\n---\n\n## Final Checklist Before Submitting\n\n### Presentation Slides\n- [ ] Renders correctly as revealjs slides\n- [ ] 10-15 slides maximum\n- [ ] No code visible anywhere\n- [ ] 2-3 polished visualizations\n- [ ] Clear model comparison table\n- [ ] No typos or formatting errors\n- [ ] Professional theme applied\n- [ ] Tested presentation timing (<5 minutes)\n\n### Technical Appendix\n- [ ] Renders correctly as HTML document\n- [ ] All code visible and commented\n- [ ] Data cleaning fully documented\n- [ ] 5+ EDA visualizations included\n- [ ] All features properly created\n- [ ] 4 models with full output\n- [ ] 10-fold CV code runs without errors\n- [ ] Diagnostic plots included\n- [ ] Sparse categories handled correctly\n- [ ] Tested that it knits without errors\n\n### Both Files\n- [ ] Proper file naming convention\n- [ ] Both .qmd source files included\n- [ ] Data sources clearly documented\n- [ ] No hard-coded file paths (use relative paths! - this should be reproducible)\n- [ ] Uploaded to Canvas on time\n\n---\n",
    "supporting": [
      "Midterm_2025_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}